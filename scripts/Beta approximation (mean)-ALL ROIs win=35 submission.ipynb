{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "data = datasets.fetch_coords_seitzman_2018(legacy_format=False)\n",
    "\n",
    "r = data['rois'][(data['networks'] == 'FrontoParietal') & (data['regions'] != 'cortexL') & (data['regions'] != 'cortexR')].copy()\n",
    "# r[\"regions\"] = data['regions'][(data['networks'] == 'FrontoParietal') & (data['regions'] != 'cortexL') & (data['regions'] != 'cortexR')]\n",
    "# r[\"coords\"] = r.apply(lambda x: (x['x'], x['y'], x['z']), axis=1)\n",
    "# dmn_coords = r['coords'].tolist()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e2c3de-bf74-4f30-968f-f382afcc9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CinguloOpercular\n",
    "# SomatomotorDorsal\n",
    "# FrontoParietal\n",
    "\n",
    "dmn_coords = [[\n",
    " (32, -81, -38),\n",
    " (-32, -78, -38),\n",
    " (-24, -76, -28),\n",
    " (24, -76, -28),\n",
    " (-6, -51, -41),\n",
    " (8, -50, -40),\n",
    " (-25, -39, -2),\n",
    " (25, -37, -2),\n",
    " (-5, -10, 9),\n",
    " (4, -8, 8),\n",
    " (-13, 17, 7),\n",
    " (12, 18, 7)],\n",
    " [\n",
    " (44, -60, -30),\n",
    " (-44, -60, -30),\n",
    " (-34, -42, -44),\n",
    " (-15, -14, 12),\n",
    " (13, -14, 12),\n",
    " (-9, -10, 0),\n",
    " (10, -8, 2)\n",
    " ],\n",
    "[(-6, -74, -42),\n",
    " (8, -72, -39),\n",
    " (-10, -62, -18),\n",
    " (10, -62, -18),\n",
    " (-33, -51, -50),\n",
    " (-12, -44, -18),\n",
    " (12, -44, -18),\n",
    " (-19, -23, 10),\n",
    " (16, -22, 9),\n",
    " (-14, -20, 1),\n",
    " (14, -19, 0),\n",
    " (-28, -10, -4),\n",
    " (-28, -10, 9),\n",
    " (29, -8, 8),\n",
    " (28, -7, -5),\n",
    " (-19, -5, -3),\n",
    " (19, -5, -4),\n",
    " (-28, -1, -3),\n",
    " (25, 2, -1),\n",
    " (25, 5, 7),\n",
    " (-25, 8, 8)],\n",
    " [(-10, -78, -28),\n",
    " (10, -78, -28),\n",
    " (-34, -72, -48),\n",
    " (34, -72, -48),\n",
    " (-31, -66, -30),\n",
    " (32, -63, -30),\n",
    " (40, -44, -38),\n",
    " (-15, -2, 19),\n",
    " (14, -1, 18)]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250989d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_map_network = dict()\n",
    "for i in range(12):\n",
    "    brain_map_network[i] = 'DMN'\n",
    "for i in range(7):\n",
    "    brain_map_network[12+i] = 'CON'\n",
    "for i in range(21):\n",
    "    brain_map_network[19+i] = 'SDN'\n",
    "for i in range(9):\n",
    "    brain_map_network[40+i] = 'FPN'\n",
    "brain_map_network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a2291-3f52-4f29-9875-1d416f93914d",
   "metadata": {},
   "source": [
    "Healthy Control - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077f375-8afd-49ff-9d61-d2f332129d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn.maskers import NiftiSpheresMasker\n",
    "from nilearn.maskers.nifti_spheres_masker import _iter_signals_from_spheres\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subjects = [10159, 10171, 10189, 10206, 10217, 10225, 10227, 10228, 10235, 10249, 10269,\n",
    "            10271, 10273, 10274, 10280, 10290, 10292, 10299, 10304, 10316, 10321, 10325, 10329, 10339, 10340,\n",
    "            10345, 10347, 10356, 10361, 10365, 10376, 10428, 10429, 10438, 10440, 10448, 10455, 10460, 10471, 10478,\n",
    "            10492, 10501, 10506, 10517, 10523, 10525, 10527, 10530]\n",
    "\n",
    "# All networks\n",
    "all_coords = [c for coords in dmn_coords for c in coords]\n",
    "\n",
    "timeseries_all = {}\n",
    "\n",
    "for subj in subjects:\n",
    "    name = \"warped_img_sub-\" + str(subj) + \"_all.nii\"\n",
    "    nifti = nib.load(name)\n",
    "\n",
    "    print(\"Processing ... \", str(subj))\n",
    "\n",
    "    # Sphere of a radius\n",
    "    masker = NiftiSpheresMasker(all_coords, radius=4, standardize=True, memory=\"nilearn_cache\", verbose=2)\n",
    "    masker.fit()\n",
    "    sphere_timeseries = _iter_signals_from_spheres(\n",
    "        masker.seeds_, \n",
    "        nifti,\n",
    "        masker.radius,\n",
    "        masker.allow_overlap)\n",
    "\n",
    "    timeseries_all[subj] = list(sphere_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728712fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "# import pandas as pd\n",
    "\n",
    "# pickle_file = './all_beta_mean_timeseries_all_rois.joblib'\n",
    "# with open(pickle_file, 'wb') as f:\n",
    "#     dump(timeseries_all, f, compress='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "\n",
    "# pickle_file = './all_beta_mean_timeseries_all_rois.joblib'\n",
    "# with open(pickle_file, 'rb') as f:\n",
    "#     timeseries_all = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(timeseries_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "subject = 10159\n",
    "# subject = 10345\n",
    "# subject = 10304\n",
    "# subject = 10273\n",
    "roi = 8\n",
    "# roi = 12\n",
    "# roi = 20\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, constrained_layout = True)\n",
    "roi8 = pd.DataFrame(timeseries_all[subject][roi]).iloc[10]\n",
    "roi8.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, ax=axs[0], density=True)\n",
    "\n",
    "params = scipy.stats.norm.fit(roi8)\n",
    "x = sorted(roi8)\n",
    "norm_pdf = stats.norm.pdf(x, params[0], params[1])\n",
    "print(params[0], params[1])\n",
    "axs[0].plot(x, norm_pdf, 'r')\n",
    "\n",
    "roi8 = pd.DataFrame(timeseries_all[subject][roi]).iloc[50]\n",
    "roi8.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, ax=axs[1], density=True)\n",
    "\n",
    "params = scipy.stats.norm.fit(roi8)\n",
    "x = sorted(roi8)\n",
    "norm_pdf = stats.norm.pdf(x, params[0], params[1])\n",
    "print(params[0], params[1])\n",
    "axs[1].plot(x, norm_pdf, 'r')\n",
    "\n",
    "roi8 = pd.DataFrame(timeseries_all[subject][roi]).iloc[100]\n",
    "roi8.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, ax=axs[2], density=True)\n",
    "\n",
    "params = scipy.stats.norm.fit(roi8)\n",
    "x = sorted(roi8)\n",
    "norm_pdf = stats.norm.pdf(x, params[0], params[1])\n",
    "print(params[0], params[1])\n",
    "axs[2].plot(x, norm_pdf, 'r')\n",
    "\n",
    "axs[1].set_xlabel(\"rs-fMRI Signal\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].set_title(\"Time Point = 10\")\n",
    "axs[1].set_title(\"Time Point = 50\")\n",
    "axs[2].set_title(\"Time Point = 100\")\n",
    "\n",
    "\n",
    "# QQ-plot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, constrained_layout = True)\n",
    "roi8 = pd.DataFrame(timeseries_all[subject][roi]).iloc[10]\n",
    "fig = sm.qqplot((roi8-roi8.mean())/roi8.std(), line='45', ax=axs[0])\n",
    "roi8 = pd.DataFrame(timeseries_all[subject][roi]).iloc[50]\n",
    "fig = sm.qqplot((roi8-roi8.mean())/roi8.std(), line='45', ax=axs[1])\n",
    "roi8 = pd.DataFrame(timeseries_all[subject][roi]).iloc[100]\n",
    "fig = sm.qqplot((roi8-roi8.mean())/roi8.std(), line='45', ax=axs[2])\n",
    "axs[0].set_title(\"Time Point = 10\")\n",
    "axs[1].set_title(\"Time Point = 50\")\n",
    "axs[2].set_title(\"Time Point = 100\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c37a66-d02a-4959-8823-eedd1547d825",
   "metadata": {},
   "source": [
    "SZ - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c4ab1-df34-4035-84ea-0423b22824d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn.maskers import NiftiSpheresMasker\n",
    "from nilearn.maskers.nifti_spheres_masker import _iter_signals_from_spheres\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "szsubjects = [50004, 50005, 50006, 50007, 50008, 50010, 50013, 50014, 50015, 50016, 50020,\n",
    "            50021, 50022, 50023, 50025, 50027, 50029, 50032, 50033, 50034, 50035, 50036,\n",
    "            50038, 50043, 50047, 50048, 50049, 50050, 50051, 50052, 50053, 50054, 50055, 50056, 50059, 50060, 50061,\n",
    "            50064, 50066, 50067, 50069, 50073, 50075, 50076, 50077, 50080, 50081, 50083, 50085]\n",
    "\n",
    "sztimeseries_all = {}\n",
    "\n",
    "# All networks\n",
    "all_coords = [c for coords in dmn_coords for c in coords]\n",
    "\n",
    "for subj in szsubjects:\n",
    "    name = \"warped_img_sub-\" + str(subj) + \"_all.nii\"\n",
    "    nifti = nib.load(name)\n",
    "\n",
    "    print(\"Processing ... \", str(subj))\n",
    "\n",
    "    # Sphere of a radius\n",
    "    masker = NiftiSpheresMasker(all_coords, radius=4, standardize=True, memory=\"nilearn_cache\", verbose=2)\n",
    "    masker.fit()\n",
    "    sphere_timeseries = _iter_signals_from_spheres(\n",
    "        masker.seeds_, \n",
    "        nifti,\n",
    "        masker.radius,\n",
    "        masker.allow_overlap)\n",
    "\n",
    "    sztimeseries_all[subj] = list(sphere_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5219b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "# import pandas as pd\n",
    "\n",
    "# pickle_file = './all_beta_mean_sztimeseries_all_rois.joblib'\n",
    "# with open(pickle_file, 'wb') as f:\n",
    "#     dump(sztimeseries_all, f, compress='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "\n",
    "# pickle_file = './all_beta_mean_sztimeseries_all_rois.joblib'\n",
    "# with open(pickle_file, 'rb') as f:\n",
    "#     sztimeseries_all = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "subject = 50007\n",
    "# subject = 10345\n",
    "# subject = 10304\n",
    "# subject = 10273\n",
    "roi = 8\n",
    "# roi = 12\n",
    "# roi = 20\n",
    "# roi = 39\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, constrained_layout = True)\n",
    "roi8 = pd.DataFrame(sztimeseries_all[subject][roi]).iloc[10]\n",
    "roi8.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, ax=axs[0], density=True)\n",
    "\n",
    "params = scipy.stats.norm.fit(roi8)\n",
    "x = sorted(roi8)\n",
    "norm_pdf = stats.norm.pdf(x, params[0], params[1])\n",
    "print(params[0], params[1])\n",
    "axs[0].plot(x, norm_pdf, 'r')\n",
    "\n",
    "roi8 = pd.DataFrame(sztimeseries_all[subject][roi]).iloc[50]\n",
    "roi8.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, ax=axs[1], density=True)\n",
    "\n",
    "params = scipy.stats.norm.fit(roi8)\n",
    "x = sorted(roi8)\n",
    "norm_pdf = stats.norm.pdf(x, params[0], params[1])\n",
    "print(params[0], params[1])\n",
    "axs[1].plot(x, norm_pdf, 'r')\n",
    "\n",
    "roi8 = pd.DataFrame(sztimeseries_all[subject][roi]).iloc[100]\n",
    "roi8.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, ax=axs[2], density=True)\n",
    "\n",
    "params = scipy.stats.norm.fit(roi8)\n",
    "x = sorted(roi8)\n",
    "norm_pdf = stats.norm.pdf(x, params[0], params[1])\n",
    "print(params[0], params[1])\n",
    "axs[2].plot(x, norm_pdf, 'r')\n",
    "\n",
    "axs[1].set_xlabel(\"rs-fMRI Signal\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].set_title(\"Time Point = 10\")\n",
    "axs[1].set_title(\"Time Point = 50\")\n",
    "axs[2].set_title(\"Time Point = 100\")\n",
    "\n",
    "\n",
    "# QQ-plot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, constrained_layout = True)\n",
    "roi8 = pd.DataFrame(timeseries_all[subject][roi]).iloc[10]\n",
    "fig = sm.qqplot((roi8-roi8.mean())/roi8.std(), line='45', ax=axs[0])\n",
    "roi8 = pd.DataFrame(timeseries_all[subject][roi]).iloc[50]\n",
    "fig = sm.qqplot((roi8-roi8.mean())/roi8.std(), line='45', ax=axs[1])\n",
    "roi8 = pd.DataFrame(timeseries_all[subject][roi]).iloc[100]\n",
    "fig = sm.qqplot((roi8-roi8.mean())/roi8.std(), line='45', ax=axs[2])\n",
    "axs[0].set_title(\"Time Point = 10\")\n",
    "axs[1].set_title(\"Time Point = 50\")\n",
    "axs[2].set_title(\"Time Point = 100\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffee6ae-217d-4eb8-83f5-e9b3ab1774b0",
   "metadata": {},
   "source": [
    "Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f404b-f2ee-4df1-bb48-1cf9e6738b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "\n",
    "all_region_pairs = list(itertools.combinations(range(len(all_coords)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73787c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corrs_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn.maskers import NiftiSpheresMasker\n",
    "from nilearn.maskers.nifti_spheres_masker import _iter_signals_from_spheres\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy.stats import beta \n",
    "from scipy.optimize import curve_fit\n",
    "from itertools import product\n",
    "\n",
    "# Minimum number of voxels\n",
    "# all_v = []\n",
    "# for x in timeseries_all[subjects[0]]:\n",
    "#     all_v.append(len(x[0]))\n",
    "# min_v = min(all_v)\n",
    "# min_v\n",
    "\n",
    "all_beta_mean = dict()\n",
    "all_beta_variance = dict()\n",
    "\n",
    "# All pairs\n",
    "for regions in tqdm(all_region_pairs): # tqdm([(8,9)]):\n",
    "\n",
    "    # beta mean\n",
    "    beta_mean = np.array([])\n",
    "    beta_variance = np.array([])\n",
    "\n",
    "    print(\"HC Processing ... region:\", regions)\n",
    "    \n",
    "    for subj in [10159]: #subjects: # [10159]:\n",
    "\n",
    "        # Correlation Analysis\n",
    "        roi_1, roi_2 = regions\n",
    "\n",
    "        ts1 = timeseries_all[subj][roi_1]\n",
    "        ts2 = timeseries_all[subj][roi_2]\n",
    "        \n",
    "        df1 = pd.DataFrame(ts1)\n",
    "        df2 = pd.DataFrame(ts2)\n",
    "\n",
    "        # time\n",
    "        T = ts1.shape[0]\n",
    "        # voxels\n",
    "        V = ts1.shape[1] # min_v\n",
    "        # sliding window\n",
    "        window_size = 35\n",
    "\n",
    "        # correlation\n",
    "        all_corrs = []\n",
    "\n",
    "        # for all the voxels (all pairs)\n",
    "#         for v in range(V):\n",
    "\n",
    "        cartesian_product = product(range(V), repeat=2)\n",
    "        for a, b in cartesian_product:\n",
    "            # correlation for the same voxel between 2 regions\n",
    "            corrs = df1[a].rolling(window_size).corr(df2[b])\n",
    "            corrs = corrs.to_frame()\n",
    "            all_corrs.append(corrs[window_size-1:].iloc[:,0].tolist())\n",
    "\n",
    "        # convert it to np array\n",
    "        all_corrs_np = np.array(all_corrs).transpose()\n",
    "\n",
    "        # Beta parameters\n",
    "        beta_all = []\n",
    "\n",
    "        for t in range(all_corrs_np.shape[0]):\n",
    "            beta_params = scipy.stats.beta.fit(all_corrs_np[t,:], floc=-1, fscale=2)\n",
    "            beta_all.append(beta_params)\n",
    "            \n",
    "            # standard errors for paramters\n",
    "#             fig, ax = plt.subplots() \n",
    "#             nbins = 100\n",
    "#             n, bins, patches = ax.hist(all_corrs_np[t,:], nbins, density=True, facecolor = 'grey', alpha = 0.5, label='before'); \n",
    "#             centers = (0.5*(bins[1:]+bins[:-1]))\n",
    "#             pars, cov = curve_fit(lambda x, a, b : beta.pdf(x, a, b, -1, 2), centers, n, p0=[beta_params[0],beta_params[1]])\n",
    "#             beta_all.append([pars[0], pars[1], 2*np.sqrt(cov[0,0]), 2*np.sqrt(cov[1,1])])\n",
    "\n",
    "        beta_all_np = np.array(beta_all)\n",
    "\n",
    "        beta_mean = np.append(beta_mean, (beta_all_np[:, 0] - beta_all_np[:, 1]) / (beta_all_np[:, 0] + beta_all_np[:, 1]))\n",
    "        beta_variance = np.append(beta_variance, \n",
    "                                  4 * beta_all_np[:, 0] * beta_all_np[:, 1] / ((beta_all_np[:, 0] + beta_all_np[:, 1])**2 * (beta_all_np[:, 0] + beta_all_np[:, 1] + 1)))\n",
    "    \n",
    "    beta_roi = str(roi_1) + \",\" + str(roi_2)\n",
    "    all_beta_mean[beta_roi] = beta_mean\n",
    "    all_beta_variance[beta_roi] = beta_variance\n",
    "    \n",
    "sz_all_beta_mean = dict()\n",
    "\n",
    "# All pairs\n",
    "for regions in tqdm(all_region_pairs):\n",
    "\n",
    "    # beta mean\n",
    "    beta_mean = np.array([])\n",
    "\n",
    "    print(\"SZ Processing ... region:\", regions)\n",
    "    \n",
    "    for subj in szsubjects:\n",
    "\n",
    "        # Correlation Analysis\n",
    "        roi_1, roi_2 = regions\n",
    "\n",
    "        ts1 = sztimeseries_all[subj][roi_1]\n",
    "        ts2 = sztimeseries_all[subj][roi_2]\n",
    "        \n",
    "        df1 = pd.DataFrame(ts1)\n",
    "        df2 = pd.DataFrame(ts2)\n",
    "\n",
    "        # time\n",
    "        T = ts1.shape[0]\n",
    "        # voxels\n",
    "        V = ts1.shape[1]\n",
    "        # sliding window\n",
    "        window_size = 35\n",
    "\n",
    "        # correlation\n",
    "        all_corrs = []\n",
    "\n",
    "        # for all the voxels\n",
    "#         for v in range(V):\n",
    "#             # correlation for the same voxel between 2 regions\n",
    "#             corrs = df1[[v]].rolling(window_size).corr(df2[[v]])\n",
    "#             all_corrs.append(corrs[window_size-1:].iloc[:,0].tolist())\n",
    "\n",
    "        cartesian_product = product(range(V), repeat=2)\n",
    "        for a, b in cartesian_product:\n",
    "            # correlation for the same voxel between 2 regions\n",
    "            corrs = df1[a].rolling(window_size).corr(df2[b])\n",
    "            corrs = corrs.to_frame()\n",
    "            all_corrs.append(corrs[window_size-1:].iloc[:,0].tolist())\n",
    "            \n",
    "        # convert it to np array\n",
    "        all_corrs_np = np.array(all_corrs).transpose()\n",
    "        \n",
    "        # Beta parameters\n",
    "        beta_all = []\n",
    "\n",
    "        for t in range(all_corrs_np.shape[0]):\n",
    "            beta_params = scipy.stats.beta.fit(all_corrs_np[t,:], floc=-1, fscale=2)\n",
    "            beta_all.append(beta_params)\n",
    "\n",
    "        beta_all_np = np.array(beta_all)\n",
    "\n",
    "        beta_mean = np.append(beta_mean, (beta_all_np[:, 0] - beta_all_np[:, 1]) / (beta_all_np[:, 0] + beta_all_np[:, 1]))\n",
    "    \n",
    "    beta_roi = str(roi_1) + \",\" + str(roi_2)\n",
    "    sz_all_beta_mean[beta_roi] = beta_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.var(all_corrs_np, axis=1)\n",
    "\n",
    "# all_beta_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"Beta variance\": all_beta_variance['8,9'], \"Sample variance\": np.var(all_corrs_np, axis=1)})\n",
    "# df.plot(xlabel=\"Time Point\", ylabel=\"Variance\", title=\"Sliding-window Variance, HC subject ID 10159, between Thalamus ROI 8 and ROI 9\")\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d9f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_corrs_np35)\n",
    "df.plot(legend=False, xlabel=\"Time Point\", ylabel=\"Correlation Coefficient\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, constrained_layout = True)\n",
    "\n",
    "s = pd.Series(all_corrs_np[10,:])\n",
    "s.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, density=True, ax=axs[0])\n",
    "\n",
    "beta_params = scipy.stats.beta.fit(s, floc=-1, fscale=2)\n",
    "x = sorted(s)\n",
    "beta_pdf = stats.beta.pdf(x, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "print(beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "axs[0].plot(x, beta_pdf, 'r')\n",
    "\n",
    "####################################################\n",
    "\n",
    "s = pd.Series(all_corrs_np[50,:])\n",
    "s.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, density=True, ax=axs[1])\n",
    "\n",
    "beta_params = scipy.stats.beta.fit(s, floc=-1, fscale=2)\n",
    "x = sorted(s)\n",
    "beta_pdf = stats.beta.pdf(x, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "print(beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "axs[1].plot(x, beta_pdf, 'r')\n",
    "\n",
    "####################################################\n",
    "\n",
    "s = pd.Series(all_corrs_np[100,:])\n",
    "s.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, density=True, ax=axs[2])\n",
    "\n",
    "beta_params = scipy.stats.beta.fit(s, floc=-1, fscale=2)\n",
    "x = sorted(s)\n",
    "beta_pdf = stats.beta.pdf(x, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "print(beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "axs[2].plot(x, beta_pdf, 'r')\n",
    "\n",
    "axs[1].set_xlabel(\"Correlation Coefficient\")\n",
    "axs[0].set_ylabel(\"Probability Density\")\n",
    "axs[0].set_title(\"Time Point = 10\")\n",
    "axs[1].set_title(\"Time Point = 50\")\n",
    "axs[2].set_title(\"Time Point = 100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, constrained_layout = True)\n",
    "\n",
    "s = pd.Series(all_corrs_np[10,:])\n",
    "s.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, density=True, ax=axs[0])\n",
    "\n",
    "beta_params = scipy.stats.beta.fit(s, floc=-1, fscale=2)\n",
    "x = sorted(s)\n",
    "beta_pdf = stats.beta.pdf(x, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "print(beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "axs[0].plot(x, beta_pdf, 'r')\n",
    "\n",
    "####################################################\n",
    "\n",
    "s = pd.Series(all_corrs_np[50,:])\n",
    "s.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, density=True, ax=axs[1])\n",
    "\n",
    "beta_params = scipy.stats.beta.fit(s, floc=-1, fscale=2)\n",
    "x = sorted(s)\n",
    "beta_pdf = stats.beta.pdf(x, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "print(beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "axs[1].plot(x, beta_pdf, 'r')\n",
    "\n",
    "####################################################\n",
    "\n",
    "s = pd.Series(all_corrs_np[100,:])\n",
    "s.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, density=True, ax=axs[2])\n",
    "\n",
    "beta_params = scipy.stats.beta.fit(s, floc=-1, fscale=2)\n",
    "x = sorted(s)\n",
    "beta_pdf = stats.beta.pdf(x, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "print(beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "axs[2].plot(x, beta_pdf, 'r')\n",
    "\n",
    "axs[1].set_xlabel(\"Correlation Coefficient\")\n",
    "axs[0].set_ylabel(\"Probability Density\")\n",
    "axs[0].set_title(\"Time Point = 10\")\n",
    "axs[1].set_title(\"Time Point = 50\")\n",
    "axs[2].set_title(\"Time Point = 100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "import scipy\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, constrained_layout = True)\n",
    "\n",
    "s = pd.Series(all_corrs_np[10,:])\n",
    "s.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, density=True, ax=axs[0])\n",
    "\n",
    "beta_params = scipy.stats.beta.fit(s, floc=-1, fscale=2)\n",
    "x = sorted(s)\n",
    "beta_pdf = stats.beta.pdf(x, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "print(beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "axs[0].plot(x, beta_pdf, 'r')\n",
    "\n",
    "####################################################\n",
    "\n",
    "s = pd.Series(all_corrs_np[50,:])\n",
    "s.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, density=True, ax=axs[1])\n",
    "\n",
    "beta_params = scipy.stats.beta.fit(s, floc=-1, fscale=2)\n",
    "x = sorted(s)\n",
    "beta_pdf = stats.beta.pdf(x, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "print(beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "axs[1].plot(x, beta_pdf, 'r')\n",
    "\n",
    "####################################################\n",
    "\n",
    "s = pd.Series(all_corrs_np[100,:])\n",
    "s.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5, density=True, ax=axs[2])\n",
    "\n",
    "beta_params = scipy.stats.beta.fit(s, floc=-1, fscale=2)\n",
    "x = sorted(s)\n",
    "beta_pdf = stats.beta.pdf(x, beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "print(beta_params[0], beta_params[1], beta_params[2], beta_params[3])\n",
    "axs[2].plot(x, beta_pdf, 'r')\n",
    "\n",
    "axs[1].set_xlabel(\"Correlation Coefficient\")\n",
    "axs[0].set_ylabel(\"Probability Density\")\n",
    "axs[0].set_title(\"Time Point = 10\")\n",
    "axs[1].set_title(\"Time Point = 50\")\n",
    "axs[2].set_title(\"Time Point = 100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59729ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import math\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, constrained_layout = True)\n",
    "\n",
    "# two-sample Kolmogorov-Smirnov test result\n",
    "test_results = []\n",
    "\n",
    "# for all timepoints\n",
    "for i in range(len(all_corrs_np)):\n",
    "    test_results.append(scipy.stats.ks_2samp(all_corrs_np[10,:], all_corrs_np[i,:]).pvalue)\n",
    "\n",
    "test_results_005_level = [x < 0.05/118 for x in test_results]\n",
    "colors = pd.Series([\"r\" if z else \"b\" for z in test_results_005_level])\n",
    "test_results_log10 = [300 if z < 1e-300 else -math.log10(z) for z in test_results]\n",
    "# colors = pd.Series([\"r\" if x < 1e-200 else \"m\" if x < 0.05 else \"b\" for x in test_results])\n",
    "\n",
    "axs[0].scatter(range(len(all_corrs_np)), test_results_log10, c=colors)\n",
    "axs[0].grid()\n",
    "\n",
    "# print(test_results)\n",
    "\n",
    "############################################################################\n",
    "\n",
    "# two-sample Kolmogorov-Smirnov test result\n",
    "test_results = []\n",
    "\n",
    "# for all timepoints\n",
    "for i in range(len(all_corrs_np)):\n",
    "    test_results.append(scipy.stats.ks_2samp(all_corrs_np[50,:], all_corrs_np[i,:]).pvalue)\n",
    "\n",
    "test_results_005_level = [x < 0.05/118 for x in test_results]\n",
    "colors = pd.Series([\"r\" if z else \"b\" for z in test_results_005_level])\n",
    "test_results_log10 = [300 if z < 1e-300 else -math.log10(z) for z in test_results]\n",
    "# colors = pd.Series([\"r\" if x < 1e-200 else \"m\" if x < 0.05 else \"b\" for x in test_results])\n",
    "\n",
    "axs[1].scatter(range(len(all_corrs_np)), test_results_log10, c=colors)\n",
    "axs[1].grid()\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# two-sample Kolmogorov-Smirnov test result\n",
    "test_results = []\n",
    "\n",
    "# for all timepoints\n",
    "for i in range(len(all_corrs_np)):\n",
    "    test_results.append(scipy.stats.ks_2samp(all_corrs_np[100,:], all_corrs_np[i,:]).pvalue)\n",
    "\n",
    "test_results_005_level = [x < 0.05/118 for x in test_results]\n",
    "colors = pd.Series([\"r\" if z else \"b\" for z in test_results_005_level])\n",
    "test_results_log10 = [300 if z < 1e-300 else -math.log10(z) for z in test_results]\n",
    "# colors = pd.Series([\"r\" if x < 1e-200 else \"m\" if x < 0.05 else \"b\" for x in test_results])\n",
    "\n",
    "axs[2].scatter(range(len(all_corrs_np)), test_results_log10, c=colors)\n",
    "axs[2].grid()\n",
    "\n",
    "axs[1].set_xlabel(\"Time Point\")\n",
    "axs[0].set_ylabel(r\"$-\\log_{10}(\\mathrm{p\\text{-}value})$\")\n",
    "axs[0].set_title(\"Time Point = 10\")\n",
    "axs[1].set_title(\"Time Point = 50\")\n",
    "axs[2].set_title(\"Time Point = 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc128f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_corrs_np25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a092b24-4f66-4d1f-8517-3534d8f6d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "# import pandas as pd\n",
    "\n",
    "# df_beta = pd.DataFrame(data=all_beta_mean)\n",
    "\n",
    "# pickle_file = './all_beta_mean_all_rois_window_35.joblib'\n",
    "# with open(pickle_file, 'wb') as f:\n",
    "#     dump(df_beta, f, compress='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9519a-fb8a-4a78-b29e-d57e2c48cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "# import pandas as pd\n",
    "\n",
    "# df_beta_sz = pd.DataFrame(data=sz_all_beta_mean)\n",
    "\n",
    "# pickle_file = './sz_all_beta_mean_all_rois_window_35.joblib'\n",
    "# with open(pickle_file, 'wb') as f:\n",
    "#     dump(df_beta_sz, f, compress='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be48600-160d-4d7b-8352-36688bb0949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "pickle_file = './all_beta_mean_all_rois_window_35.joblib'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    df_beta = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852865cf-5d0b-415a-bef1-8e65c5308793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "pickle_file = './sz_all_beta_mean_all_rois_window_35.joblib'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    df_beta_sz = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc465c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_mean = (beta_all_np[:, 0] - beta_all_np[:, 1]) / (beta_all_np[:, 0] + beta_all_np[:, 1])\n",
    "x = np.arange(len(beta_mean))\n",
    "\n",
    "beta_variance = (beta_all_np[:, 0]*beta_all_np[:, 1])*4 / ((beta_all_np[:, 0] + beta_all_np[:, 1])**2 * (beta_all_np[:, 0] + beta_all_np[:, 1] + 1))\n",
    "beta_std_err = beta_variance ** 0.5 / (257*257)**0.5\n",
    "\n",
    "plt.grid()\n",
    "plt.errorbar(x, beta_mean, 2*beta_std_err, linestyle='None', marker='*')\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.xlabel(\"Time Point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e031ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(min(beta_mean), max(beta_mean), min(beta_std), max(beta_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95171e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "(min(beta_mean), max(beta_mean), min(beta_std_err), max(beta_std_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c160e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_all_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ae683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"α\" : beta_all_np[:, 0], \"β\" : beta_all_np[:, 1]})\n",
    "#df.plot()\n",
    "\n",
    "# Change the way how beta_all is calculated earlier, using curve fit\n",
    "x = np.arange(len(beta_all_np[:, 0]))\n",
    "plt.grid()\n",
    "plt.errorbar(x, beta_all_np[:, 0], beta_all_np[:, 2], linestyle='None', marker='*')\n",
    "plt.errorbar(x, beta_all_np[:, 1], beta_all_np[:, 3], linestyle='None', marker='*')\n",
    "plt.legend([\"α\", \"β\"])\n",
    "plt.ylabel(\"Beta Paramter Values\")\n",
    "plt.xlabel(\"Time Point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd87e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "# KS test\n",
    "test_results = []\n",
    "\n",
    "import scipy\n",
    "for y in tqdm(list(df_beta)):\n",
    "    c = df_beta[y]\n",
    "    z = df_beta_sz[y]\n",
    "    test_results.append(scipy.stats.ks_2samp(c, z).pvalue)\n",
    "\n",
    "df_tests = pd.DataFrame({\"ks test\": test_results})\n",
    "df_tests.index = list(df_beta)\n",
    "print(df_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e94a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "# KS test - Effect Size\n",
    "test_results_d = []\n",
    "\n",
    "import scipy\n",
    "for y in tqdm(list(df_beta)):\n",
    "    if -math.log10(df_tests[\"ks test\"][y]) > 4.4:\n",
    "        c = df_beta[y]\n",
    "        z = df_beta_sz[y]\n",
    "        n1 = c.shape[0]\n",
    "        n2 = z.shape[0]\n",
    "        test_results_d.append(scipy.stats.ks_2samp(c, z).statistic / (n1*n2/(n1+n2))**0.5)\n",
    "    else:\n",
    "        test_results_d.append(-1)\n",
    "\n",
    "df_tests_d = pd.DataFrame({\"ks test\": test_results_d})\n",
    "df_tests_d.index = list(df_beta)\n",
    "print(df_tests_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2c099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "df_tests[\"ks test\"].apply(lambda x : -math.log10(x)).plot.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5)\n",
    "plt.title(\"HC vs SZ\")\n",
    "plt.xlabel(\"-log10 p-value\")\n",
    "plt.ylabel(\"Count of ROI pairs\")\n",
    "plt.show()\n",
    "\n",
    "bins = [0, 4.4]\n",
    "bins.extend(list(range(25, 200, 25)))\n",
    "x = df_tests[\"ks test\"].apply(lambda x : -math.log10(x)).value_counts(bins=bins)\n",
    "print(x)\n",
    "print(x / x.sum() * 100)\n",
    "\n",
    "# # KL divergence\n",
    "# df_kld[\"kl divergence\"].plot.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "# bins = list(range(0, 20, 3))\n",
    "# x = df_kld[\"kl divergence\"].value_counts(bins=bins)\n",
    "# print(x / x.sum() * 100)\n",
    "\n",
    "a = df_tests[\"ks test\"].sort_values(ascending=True).index[0:50]\n",
    "print(\"#################################################\")\n",
    "print(\"ks test:\")\n",
    "print(a)\n",
    "\n",
    "network_pairs = []\n",
    "for roi_pair in a:\n",
    "    a1, a2 = roi_pair.split(',')\n",
    "    network_pairs.append((brain_map_network[int(a1)], brain_map_network[int(a2)]))\n",
    "print(Counter(network_pairs))\n",
    "\n",
    "# print(\"#################################################\")\n",
    "# print(\"kl divergence:\")\n",
    "# b = df_kld[\"kl divergence\"].sort_values(ascending=False).index[0:50]\n",
    "# print(b)\n",
    "\n",
    "# network_pairs = []\n",
    "# for roi_pair in b:\n",
    "#     a1, a2 = roi_pair.split(',')\n",
    "#     network_pairs.append((brain_map_network[int(a1)], brain_map_network[int(a2)]))\n",
    "# print(Counter(network_pairs))\n",
    "\n",
    "# print(\"#################################################\")\n",
    "# print(\"Common to both:\")\n",
    "# both_tests_list = set(a).intersection(set(b))\n",
    "# print(both_tests_list)\n",
    "\n",
    "# network_pairs = []\n",
    "# for roi_pair in both_tests_list:\n",
    "#     a1, a2 = roi_pair.split(',')\n",
    "#     network_pairs.append((brain_map_network[int(a1)], brain_map_network[int(a2)]))\n",
    "# print(Counter(network_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "df_tests_d[\"ks test\"].plot.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5)\n",
    "plt.title(\"HC vs SZ\")\n",
    "plt.xlabel(\"Effect size\")\n",
    "plt.ylabel(\"Count of ROI pairs\")\n",
    "plt.show()\n",
    "\n",
    "bins = [-1, 0, 0.001, 0.002, 0.0035, 0.007, 1]\n",
    "x = df_tests_d[\"ks test\"].value_counts(bins=bins)\n",
    "print(x)\n",
    "print(x / x.sum() * 100)\n",
    "\n",
    "# # KL divergence\n",
    "# df_kld[\"kl divergence\"].plot.hist(grid=True, bins=20, rwidth=0.9, alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "# bins = list(range(0, 20, 3))\n",
    "# x = df_kld[\"kl divergence\"].value_counts(bins=bins)\n",
    "# print(x / x.sum() * 100)\n",
    "\n",
    "# a = df_tests_d[\"ks test\"].sort_values(ascending=True).index[0:44]\n",
    "a = df_tests_d[\"ks test\"][df_tests_d[\"ks test\"]>0.0035].index\n",
    "print(\"#################################################\")\n",
    "print(\"ks test:\")\n",
    "print(a)\n",
    "\n",
    "network_pairs = []\n",
    "for roi_pair in a:\n",
    "    a1, a2 = roi_pair.split(',')\n",
    "    network_pairs.append((brain_map_network[int(a1)], brain_map_network[int(a2)]))\n",
    "print(Counter(network_pairs))\n",
    "\n",
    "# print(\"#################################################\")\n",
    "# print(\"kl divergence:\")\n",
    "# b = df_kld[\"kl divergence\"].sort_values(ascending=False).index[0:50]\n",
    "# print(b)\n",
    "\n",
    "# network_pairs = []\n",
    "# for roi_pair in b:\n",
    "#     a1, a2 = roi_pair.split(',')\n",
    "#     network_pairs.append((brain_map_network[int(a1)], brain_map_network[int(a2)]))\n",
    "# print(Counter(network_pairs))\n",
    "\n",
    "# print(\"#################################################\")\n",
    "# print(\"Common to both:\")\n",
    "# both_tests_list = set(a).intersection(set(b))\n",
    "# print(both_tests_list)\n",
    "\n",
    "# network_pairs = []\n",
    "# for roi_pair in both_tests_list:\n",
    "#     a1, a2 = roi_pair.split(',')\n",
    "#     network_pairs.append((brain_map_network[int(a1)], brain_map_network[int(a2)]))\n",
    "# print(Counter(network_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests[\"ks test\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6e0cc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "network_pairs = []\n",
    "\n",
    "# for i, y in enumerate(df_tests[\"ks test\"].sort_values(ascending=True).index[0:50]):\n",
    "for i, y in enumerate(df_tests_d[\"ks test\"][df_tests_d[\"ks test\"]>0.0035].index):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    c = df_beta[y]\n",
    "    z = df_beta_sz[y]\n",
    "    \n",
    "    df = pd.DataFrame({\"HC\": c, \"BP\": z})\n",
    "    print(\"Mean: (HC) \", c.mean(), \"(BP) \", z.mean())\n",
    "    print(\"STD: (HC) \", c.std(), \"(BP) \", z.std())\n",
    "    print(-math.log10(scipy.stats.ks_2samp(c, z).pvalue))\n",
    "    df.plot.hist(grid=True, bins=20, rwidth=0.9, ax=ax, alpha=0.5, density=True)\n",
    "    ax.set_title(\"HC vs BP, Fitted means (Window = 35): ROI \" + y + \", Top \" + str(i+1) + \", -log10 p-value = \" + str(round(-math.log10(scipy.stats.ks_2samp(c, z).pvalue))))\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    plt.show()\n",
    "    \n",
    "    a1, a2 = y.split(',')\n",
    "    network_pairs.append((brain_map_network[int(a1)], brain_map_network[int(a2)], \"hyper\" if z.mean() > c.mean() else \"hypo\"))\n",
    "\n",
    "print(Counter(network_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace70c1-ee6e-4ebd-ba9f-ff301c30ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "pickle_file = './beta_testing_results_2.joblib'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    df_testing_results = load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
